{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "shhb80niwd",
   "metadata": {},
   "source": [
    "### Registro de Voz\n",
    "\n",
    "Registrar nuevas voces en el sistema de reconocimiento de hablantes.\n",
    "\n",
    "**Pasos:** Importar dependencias → Configurar rutas → Cargar modelo → Grabar audio → Generar embedding → Guardar en BD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dsth25r577l",
   "metadata": {},
   "source": [
    "#### 1. Importar dependencias\n",
    "Librerías para grabación, procesamiento de audio y generación de embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e83fb951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\work_jhonatan_becerra\\speach-recognition\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The torchaudio backend is switched to 'soundfile'. Note that 'sox_io' is not supported on Windows.\n",
      "d:\\work_jhonatan_becerra\\speach-recognition\\venv\\Lib\\site-packages\\speechbrain\\utils\\torch_audio_backend.py:22: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n",
      "torchvision is not available - cannot save figures\n",
      "The torchaudio backend is switched to 'soundfile'. Note that 'sox_io' is not supported on Windows.\n",
      "d:\\work_jhonatan_becerra\\speach-recognition\\venv\\Lib\\site-packages\\speechbrain\\utils\\torch_audio_backend.py:22: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "\n",
    "from speechbrain.pretrained import EncoderClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n8qhvmkjcr",
   "metadata": {},
   "source": [
    "#### 2. Configurar directorios\n",
    "Define rutas del modelo, base de datos de voces y directorio temporal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e022fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_DIR: d:\\work_jhonatan_becerra\\speach-recognition\\models\\spkrec-ecapa-voxceleb\n",
      "VOICES_DB: d:\\work_jhonatan_becerra\\speach-recognition\\voices_db\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = os.path.abspath(\"..\")\n",
    "\n",
    "MODEL_DIR = os.path.join(\n",
    "    BASE_DIR,\n",
    "    \"models\",\n",
    "    \"spkrec-ecapa-voxceleb\"\n",
    ")\n",
    "\n",
    "VOICES_DB = os.path.join(BASE_DIR, \"voices_db\")\n",
    "AUDIO_TMP = os.path.join(BASE_DIR, \"audio_tmp\")\n",
    "\n",
    "os.makedirs(VOICES_DB, exist_ok=True)\n",
    "os.makedirs(AUDIO_TMP, exist_ok=True)\n",
    "\n",
    "print(\"MODEL_DIR:\", MODEL_DIR)\n",
    "print(\"VOICES_DB:\", VOICES_DB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ufzuorcvwo",
   "metadata": {},
   "source": [
    "#### 3. Cargar modelo ECAPA-TDNN\n",
    "Carga el modelo SpeechBrain pre-entrenado en VoxCeleb (genera embeddings de 192 dimensiones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7db92241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado correctamente\n"
     ]
    }
   ],
   "source": [
    "classifier = EncoderClassifier.from_hparams(\n",
    "    source=MODEL_DIR,\n",
    "    savedir=MODEL_DIR,\n",
    "    run_opts={\"device\": \"cpu\"}\n",
    ")\n",
    "\n",
    "print(\"Modelo cargado correctamente\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qim9tg9rf3",
   "metadata": {},
   "source": [
    "#### 4. Definir parámetros de audio\n",
    "16 kHz, mono, 10 segundos de duración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "897fb19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16_000\n",
    "CHANNELS = 1\n",
    "DURATION_SEC = 10\n",
    "\n",
    "AUDIO_PATH = os.path.join(AUDIO_TMP, \"registro.wav\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jbtcxmaar9k",
   "metadata": {},
   "source": [
    "#### 5. Grabar voz desde micrófono\n",
    "Captura 10 segundos de audio y guarda como WAV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37b56a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabando voz por 10 segundos...\n",
      "Audio capturado en: d:\\work_jhonatan_becerra\\speach-recognition\\audio_tmp\\registro.wav\n"
     ]
    }
   ],
   "source": [
    "print(\"Grabando voz por 10 segundos...\")\n",
    "audio = sd.rec(\n",
    "    int(DURATION_SEC * SAMPLE_RATE),\n",
    "    samplerate=SAMPLE_RATE,\n",
    "    channels=CHANNELS,\n",
    "    dtype=\"float32\"\n",
    ")\n",
    "sd.wait()\n",
    "\n",
    "sf.write(AUDIO_PATH, audio, SAMPLE_RATE)\n",
    "print(\"Audio capturado en:\", AUDIO_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g5t53pfshb6",
   "metadata": {},
   "source": [
    "#### 6. Cargar y normalizar audio\n",
    "Convierte a mono y normaliza amplitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6278b210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waveform listo: torch.Size([1, 160000])\n"
     ]
    }
   ],
   "source": [
    "waveform, sr = torchaudio.load(AUDIO_PATH)\n",
    "\n",
    "assert sr == SAMPLE_RATE, \"Sample rate incorrecto\"\n",
    "\n",
    "waveform = waveform.mean(dim=0, keepdim=True)\n",
    "waveform = waveform / torch.max(torch.abs(waveform))\n",
    "\n",
    "print(\"Waveform listo:\", waveform.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "etts842qxbt",
   "metadata": {},
   "source": [
    "#### 7. Generar embedding de voz\n",
    "Extrae vector de 192 dimensiones que representa las características únicas de la voz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d7b8376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generado: (192,)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    embedding = classifier.encode_batch(waveform)\n",
    "\n",
    "embedding = embedding.squeeze().cpu().numpy()\n",
    "\n",
    "print(\"Embedding generado:\", embedding.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k0m197zh6ol",
   "metadata": {},
   "source": [
    "#### 8. Guardar embedding en base de datos\n",
    "Solicita ID de la persona y guarda el embedding como `{persona_id}.npy` en voices_db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c1d753d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voz registrada correctamente en: d:\\work_jhonatan_becerra\\speach-recognition\\voices_db\\jhonatan.npy\n"
     ]
    }
   ],
   "source": [
    "persona_id = input(\"Ingrese el identificador de la persona (ej: jhonatan): \").strip()\n",
    "\n",
    "assert persona_id, \"ID inválido\"\n",
    "\n",
    "save_path = os.path.join(VOICES_DB, f\"{persona_id}.npy\")\n",
    "np.save(save_path, embedding)\n",
    "\n",
    "print(\"Voz registrada correctamente en:\", save_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
